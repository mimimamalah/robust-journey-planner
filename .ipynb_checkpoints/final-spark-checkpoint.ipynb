{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c27c6c7-0596-4342-99d4-57bdb3ca1ea1",
   "metadata": {},
   "source": [
    "# Data Exploration and Data Pre-processing\n",
    "\n",
    "This Notebook sets up and configures a Spark session that involves processing large datasets from Swiss public transportation systems (SBB). The code includes detailed data cleaning, filtering, and transformation steps to prepare the data for further analysis.The goal is to prepare the data for robust journey planning applications by filtering out irrelevant records, managing data types, and ensuring data integrity and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cee8d3-e391-4a0f-9cf6-6edfbef500a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '1000M', 'executorMemory': '4G', 'executorCores': 4, 'numExecutors': 10, 'conf': {'spark.executorEnv.USERNAME': 'malahlou', 'spark.executorEnv.HADOOP_DEFAULT_FS': 'hdfs://iccluster067.iccluster.epfl.ch:8020', 'mapreduce.input.fileinputformat.input.dir.recursive': True, 'spark.sql.extensions': 'com.hortonworks.spark.sql.rule.Extensions', 'spark.kryo.registrator': 'com.qubole.spark.hiveacid.util.HiveAcidKyroRegistrator', 'spark.sql.hive.hiveserver2.jdbc.url': 'jdbc:hive2://iccluster065.iccluster.epfl.ch:2181,iccluster080.iccluster.epfl.ch:2181,iccluster066.iccluster.epfl.ch:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2', 'spark.datasource.hive.warehouse.read.mode': 'JDBC_CLUSTER', 'spark.driver.extraClassPath': '/opt/cloudera/parcels/SPARK3/lib/hwc_for_spark3/hive-warehouse-connector-spark3-assembly-1.0.0.3.3.7190.2-1.jar', 'spark.executor.extraClassPath': '/opt/cloudera/parcels/SPARK3/lib/hwc_for_spark3/hive-warehouse-connector-spark3-assembly-1.0.0.3.3.7190.2-1.jar', 'spark.kryoserializer.buffer.max': '2000m'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3664</td><td>application_1713270977862_3938</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster080.iccluster.epfl.ch:8088/proxy/application_1713270977862_3938/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster076.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1713270977862_3938_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3670</td><td>application_1713270977862_3947</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster080.iccluster.epfl.ch:8088/proxy/application_1713270977862_3947/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1713270977862_3947_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3672</td><td>application_1713270977862_3949</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster080.iccluster.epfl.ch:8088/proxy/application_1713270977862_3949/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1713270977862_3949_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3673</td><td>application_1713270977862_3950</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster080.iccluster.epfl.ch:8088/proxy/application_1713270977862_3950/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1713270977862_3950_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3674</td><td>application_1713270977862_3953</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster080.iccluster.epfl.ch:8088/proxy/application_1713270977862_3953/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster076.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1713270977862_3953_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3675</td><td>application_1713270977862_3955</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster080.iccluster.epfl.ch:8088/proxy/application_1713270977862_3955/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster076.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1713270977862_3955_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3683</td><td>application_1713270977862_3964</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster080.iccluster.epfl.ch:8088/proxy/application_1713270977862_3964/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1713270977862_3964_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\": {\n",
    "        \"mapreduce.input.fileinputformat.input.dir.recursive\": true,\n",
    "        \"spark.sql.extensions\": \"com.hortonworks.spark.sql.rule.Extensions\",\n",
    "        \"spark.kryo.registrator\": \"com.qubole.spark.hiveacid.util.HiveAcidKyroRegistrator\",\n",
    "        \"spark.sql.hive.hiveserver2.jdbc.url\": \"jdbc:hive2://iccluster065.iccluster.epfl.ch:2181,iccluster080.iccluster.epfl.ch:2181,iccluster066.iccluster.epfl.ch:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2\",\n",
    "        \"spark.datasource.hive.warehouse.read.mode\": \"JDBC_CLUSTER\",\n",
    "        \"spark.driver.extraClassPath\": \"/opt/cloudera/parcels/SPARK3/lib/hwc_for_spark3/hive-warehouse-connector-spark3-assembly-1.0.0.3.3.7190.2-1.jar\",\n",
    "        \"spark.executor.extraClassPath\": \"/opt/cloudera/parcels/SPARK3/lib/hwc_for_spark3/hive-warehouse-connector-spark3-assembly-1.0.0.3.3.7190.2-1.jar\",\n",
    "        \"spark.kryoserializer.buffer.max\": \"2000m\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16c96992-7d6a-4682-beab-bd88b207778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Spark name:livy-session-3538, version:3.3.2.3.3.7190.2-1"
     ]
    }
   ],
   "source": [
    "print(f'Start Spark name:{spark._sc.appName}, version:{spark.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "87c1dec4-29f9-46e1-b3dd-42f520b58a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local username=malahlou\n",
      "hadoop_fs=hdfs://iccluster067.iccluster.epfl.ch:8020\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "import os\n",
    "username=os.getenv('USER', 'anonymous')\n",
    "hadoop_fs=os.getenv('HADOOP_DEFAULT_FS', 'hdfs://iccluster067.iccluster.epfl.ch:8020')\n",
    "print(f\"local username={username}\\nhadoop_fs={hadoop_fs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66383f2c-e2c4-45f5-a609-228be7e0b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote username=malahlou\n",
      "hadoop_fs=hdfs://iccluster067.iccluster.epfl.ch:8020"
     ]
    }
   ],
   "source": [
    " # (prevent deprecated np.bool error since numpy 1.24, until a new version of pandas/Spark fixes this)\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "username=spark.conf.get('spark.executorEnv.USERNAME', 'anonymous')\n",
    "hadoop_fs=spark.conf.get('spark.executorEnv.HADOOP_DEFAULT_FS','hdfs://iccluster067.iccluster.epfl.ch:8020')\n",
    "print(f\"remote username={username}\\nhadoop_fs={hadoop_fs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "166bcc13-efee-44ce-9d77-34aaadb99302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data cleaning, remove empty rows\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, unix_timestamp, lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9b905-eb1f-4586-9339-f346bc84c2e3",
   "metadata": {},
   "source": [
    "We need to filter our data.\n",
    "We will keep:\n",
    "- Data from 2024 and after (need to know if needed or not, we will start with this as a sample if it works we will re run with more years)\n",
    "- We keep only data that is REAL (homework 3)\n",
    "- We keep only data where the departure is after the arrival  (homework 2)\n",
    "- we remove null values\n",
    "- We keep the trips at \"reasonable hours of the day, and on a typical business day\"\n",
    "- We remove additional trips\n",
    "- We remove trips where the transport do not stop\n",
    "- We remove failed trips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e95e1ba-8d7e-4d40-b58d-72773cd87c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Should we take only data from 2024 or not \n",
    "istdaten = spark.read.orc('/data/sbb/orc/istdaten').filter(col(\"year\").cast(\"int\") == 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf5e11-b0b3-439b-9738-8663ec9e4c0d",
   "metadata": {},
   "source": [
    "We make sure we only take Lausanne Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3fc8c0e5-02f1-4b92-bb24-85a1d0529327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import data from the previous assignment\n",
    "lausanne_stops = spark.sql(f\"\"\"SELECT * FROM {username}.sbb_stops_lausanne_region\"\"\")\n",
    "lausanne_stop_times = spark.sql(f\"\"\"SELECT * FROM {username}.sbb_stop_times_lausanne_region\"\"\")\n",
    "\n",
    "# Extract stop IDs from Lausanne stops and convert them to lowercase\n",
    "lausanne_stop_ids = lausanne_stops.select(lower(col(\"stop_id\")).alias(\"stop_id\")).distinct()\n",
    "\n",
    "# Convert Lausanne stop IDs DataFrame to a list\n",
    "lausanne_stop_ids_list = [row.stop_id for row in lausanne_stop_ids.collect()]\n",
    "\n",
    "# Ensure that the 'BPUIC' field in istdaten is also treated as 'stop_id' and convert it to lowercase before comparison\n",
    "istdaten = istdaten.withColumn(\"stop_id\", lower(col(\"BPUIC\"))).filter(col(\"stop_id\").isin(lausanne_stop_ids_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f220f42-3b98-4fe8-aeaa-359efd8240f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "istdaten = istdaten.filter((istdaten['ZUSATZFAHRT_TF'] == False) # additional trips\n",
    "                                       & (istdaten['DURCHFAHRT_TF'] == False) # transport do not stop\n",
    "                                       & (istdaten['FAELLT_AUS_TF'] == False)) # failed trips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "074a99ce-8486-4bd3-bd8f-84207ae0395d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|AN_PROGNOSE_STATUS|  count|\n",
      "+------------------+-------+\n",
      "|          PROGNOSE|6146211|\n",
      "|                  | 404888|\n",
      "|              REAL| 209790|\n",
      "|         UNBEKANNT|  29414|\n",
      "+------------------+-------+"
     ]
    }
   ],
   "source": [
    "istdaten.groupBy(\"AN_PROGNOSE_STATUS\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad345d-4188-48ea-8da8-236a586f238b",
   "metadata": {},
   "source": [
    "We will only keep those who have REAL as status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29b5eda0-b519-47ed-bf03-c52a5d82b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "istdaten = istdaten.filter((col(\"AN_PROGNOSE_STATUS\") == \"REAL\") & (col(\"AB_PROGNOSE_STATUS\") == \"REAL\"))\n",
    "istdaten = istdaten.dropna(subset=[\"ABFAHRTSZEIT\", 'BPUIC', 'HALTESTELLEN_NAME', 'PRODUKT_ID', 'FAHRT_BEZEICHNER', 'BETRIEBSTAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e4fa089-af88-4040-b82e-844de27e7f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "istdaten = istdaten.dropna(subset=[\"ABFAHRTSZEIT\", 'BPUIC', 'HALTESTELLEN_NAME', 'PRODUKT_ID', 'FAHRT_BEZEICHNER', 'BETRIEBSTAG']) \\\n",
    "    .select(\"AB_PROGNOSE\", \"ABFAHRTSZEIT\", \"AN_PROGNOSE\",\"ANKUNFTSZEIT\",  'BPUIC', 'HALTESTELLEN_NAME', 'PRODUKT_ID', 'FAHRT_BEZEICHNER', 'BETRIEBSTAG') \\\n",
    "    .withColumnRenamed(\"AB_PROGNOSE\", \"departure_time_actual\") \\\n",
    "    .withColumnRenamed(\"ABFAHRTSZEIT\", \"departure_time_scheduled\") \\\n",
    "    .withColumnRenamed(\"AN_PROGNOSE\", \"arrival_time_actual\") \\\n",
    "    .withColumnRenamed(\"ANKUNFTSZEIT\", \"arrival_time_scheduled\") \\\n",
    "    .withColumnRenamed(\"HALTESTELLEN_NAME\", \"station_name\") \\\n",
    "    .withColumnRenamed(\"BETRIEBSTAG\", \"day\") \\\n",
    "    .withColumnRenamed('PRODUKT_ID', \"transport_type\") \\\n",
    "    .withColumnRenamed(\"FAHRT_BEZEICHNER\", \"trip_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "abaee48f-6132-476b-ac8a-a47306915b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------------+-------------------+----------------------+-------+-----------------------+--------------+----------------+----------+\n",
      "|departure_time_actual|departure_time_scheduled|arrival_time_actual|arrival_time_scheduled|BPUIC  |station_name           |transport_type|trip_id         |day       |\n",
      "+---------------------+------------------------+-------------------+----------------------+-------+-----------------------+--------------+----------------+----------+\n",
      "|27.02.2024 06:05:37  |27.02.2024 06:06        |27.02.2024 06:05:32|27.02.2024 06:06      |8570064|Cheseaux-sur-L., Pâquis|Bus           |85:801:42501-240|27.02.2024|\n",
      "|27.02.2024 06:21:00  |27.02.2024 06:20        |27.02.2024 06:20:53|27.02.2024 06:20      |8570064|Cheseaux-sur-L., Pâquis|Bus           |85:801:42502-240|27.02.2024|\n",
      "+---------------------+------------------------+-------------------+----------------------+-------+-----------------------+--------------+----------------+----------+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "istdaten.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "66c5129d-3aff-4c11-a2aa-3d1806fac2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate departure delays (only those are relevant)\n",
    "# Apply transformations to calculate the unix timestamp of departure times\n",
    "istdaten_with_timestamps = istdaten.withColumn(\n",
    "    \"departure_time_actual_unix\",\n",
    "    F.unix_timestamp(\"departure_time_actual\", \"dd.MM.yyyy HH:mm:ss\")\n",
    ").withColumn(\n",
    "    \"departure_time_scheduled_unix\",\n",
    "    F.unix_timestamp(\"departure_time_scheduled\", \"dd.MM.yyyy HH:mm\")\n",
    ")\n",
    "\n",
    "# Calculate the arrival delay in minutes\n",
    "istdaten_with_timestamps = istdaten_with_timestamps.withColumn(\n",
    "    \"arrival_delay\",\n",
    "    (istdaten_with_timestamps[\"departure_time_actual_unix\"] - istdaten_with_timestamps[\"departure_time_scheduled_unix\"]) / 60\n",
    ")\n",
    "\n",
    "istdaten_with_timestamps = istdaten_with_timestamps.na.drop(subset=[\"arrival_delay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e5904da-6ddd-4460-926b-a112ddd09d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, dayofmonth, month, year\n",
    "\n",
    "istdaten_with_timestamps = istdaten_with_timestamps.withColumn(\n",
    "    \"dayofmonth\",\n",
    "    dayofmonth(F.from_unixtime(\"departure_time_scheduled_unix\"))\n",
    ").withColumn(\n",
    "    \"month\",\n",
    "    month(F.from_unixtime(\"departure_time_scheduled_unix\"))\n",
    ").withColumn(\n",
    "    \"hour\",\n",
    "    hour(F.from_unixtime(\"departure_time_scheduled_unix\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a5abd106-8640-4333-8f8a-b078826e755c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------------+-------------------+----------------------+-------+-----------------------+--------------+----------------+----------+--------------------------+-----------------------------+--------------------+----------+-----+----+\n",
      "|departure_time_actual|departure_time_scheduled|arrival_time_actual|arrival_time_scheduled|BPUIC  |station_name           |transport_type|trip_id         |day       |departure_time_actual_unix|departure_time_scheduled_unix|arrival_delay       |dayofmonth|month|hour|\n",
      "+---------------------+------------------------+-------------------+----------------------+-------+-----------------------+--------------+----------------+----------+--------------------------+-----------------------------+--------------------+----------+-----+----+\n",
      "|27.02.2024 06:05:37  |27.02.2024 06:06        |27.02.2024 06:05:32|27.02.2024 06:06      |8570064|Cheseaux-sur-L., Pâquis|Bus           |85:801:42501-240|27.02.2024|1709010337                |1709010360                   |-0.38333333333333336|27        |2    |6   |\n",
      "|27.02.2024 06:21:00  |27.02.2024 06:20        |27.02.2024 06:20:53|27.02.2024 06:20      |8570064|Cheseaux-sur-L., Pâquis|Bus           |85:801:42502-240|27.02.2024|1709011260                |1709011200                   |1.0                 |27        |2    |6   |\n",
      "+---------------------+------------------------+-------------------+----------------------+-------+-----------------------+--------------+----------------+----------+--------------------------+-----------------------------+--------------------+----------+-----+----+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "istdaten_with_timestamps.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1219244f-553d-4555-a92a-413950bc61ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "istdaten_with_timestamps = istdaten_with_timestamps.where(istdaten_with_timestamps.arrival_time_actual <= istdaten_with_timestamps.departure_time_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "105a90b8-9a1b-4eaf-9601-128a9d2f4c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "condition = ' AND '.join([f\"(trim({c}) != '' OR {c} IS NULL)\" for c in istdaten_with_timestamps.columns])\n",
    "istdaten_df = istdaten_with_timestamps.filter(condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddcd2f5-ba05-4771-a5a8-0ba851e1836b",
   "metadata": {},
   "source": [
    "We keep the trips at \"reasonable hours of the day, and on a typical business day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5dea188c-342d-4183-b277-ace39b70d83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@F.udf\n",
    "def get_hour(timestamp):\n",
    "    return int(timestamp.time().hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60816132-04f7-4eb7-9296-3adc7930ba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "istdaten_df = istdaten_df.withColumn('day_of_week', F.dayofweek(istdaten_df.departure_time_scheduled))\n",
    "istdaten_df = istdaten_df.where((get_hour(istdaten_df.arrival_time_scheduled) >= 6)\n",
    "                                          & (get_hour(istdaten_df.arrival_time_scheduled) <= 22)\n",
    "                                          & (istdaten_df.day_of_week >= 2) \n",
    "                                          & (istdaten_df.day_of_week <= 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2cfa3428-2359-4e1a-9a91-0292e2dcda89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stops = spark.sql(f\"\"\"SELECT * FROM com490.geo_shapes\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "29a1132b-8786-4f19-ab55-2782043d4b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stops.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44424519-1923-4c18-8b74-c4d2db7b8e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
