{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eda96b6-59c5-4a05-8beb-dc58794aeb61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from path_utils import *\n",
    "from time_utils import *\n",
    "from probability_computing import *\n",
    "from validation import *\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "spark = SparkSession.builder.appName(\"Router\").master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def8aeda-8d12-4ca0-88e2-94503c0d6ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local username=ahominal\n",
      "hadoop_fs=hdfs://iccluster067.iccluster.epfl.ch:8020\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "username=os.getenv('USER', 'anonymous')\n",
    "hadoop_fs=os.getenv('HADOOP_DEFAULT_FS', 'hdfs://iccluster067.iccluster.epfl.ch:8020')\n",
    "print(f\"local username={username}\\nhadoop_fs={hadoop_fs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830a8b2-a23e-4372-98ae-8eb764b193df",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "### Data Loading\n",
    "\n",
    "- Load everything to PandasDF in local (to diplay on graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcc88e4-da90-4969-b91a-a4ee525323ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/04 19:41:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/04 19:41:09 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Graph data\n",
    "edge_path = f\"/user/{username}/graph/all_edges\"\n",
    "all_edge = spark.read.orc(edge_path)\n",
    "df_all_edge = all_edge.toPandas()\n",
    "\n",
    "#Transform into seconds \n",
    "df_all_edge[\"start_time\"]=df_all_edge[\"start_time\"].apply(lambda x: None if x is None else get_sec(x))\n",
    "df_all_edge[\"end_time\"]=df_all_edge[\"end_time\"].apply(lambda x: None if x is None else get_sec(x))\n",
    "df_all_edge = df_all_edge[~df_all_edge[\"expected_travel_time\"].isnull()]\n",
    "\n",
    "node_path = f\"/user/{username}/graph/nodes_area\"\n",
    "all_nodes = spark.read.orc(node_path)\n",
    "df_all_nodes = all_nodes.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2069af-6e14-44c1-945b-907a54983daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expected_travel_time                    60.0\n",
       "start_stop_id                        8592050\n",
       "start_time                           59580.0\n",
       "trip_id                 1.TA.91-m2-j24-1.1.H\n",
       "end_stop_id                          8591818\n",
       "end_time                             59640.0\n",
       "is_walking                                 0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_edge.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ac0753-b4aa-4fdc-9946-c0ad069766fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify negative expected_travel_time\n",
    "neg_mask = df_all_edge['expected_travel_time'] < 0\n",
    "# Make the expected_travel_time positive\n",
    "df_all_edge.loc[neg_mask, 'expected_travel_time'] *= -1\n",
    "df_all_edge.loc[neg_mask, ['start_time', 'end_time']] = df_all_edge.loc[neg_mask, ['end_time', 'start_time']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffe1bc7-0cc7-439a-9319-22d004e47214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Delay data\n",
    "all_delays_path = f\"/user/{username}/delay/all_delays\"\n",
    "all_delays = spark.read.orc(all_delays_path)\n",
    "total_delays = all_delays.count()\n",
    "\n",
    "avg_delay_path = f\"/user/{username}/delay/avg_delay\"\n",
    "avg_delay = spark.read.orc(avg_delay_path)\n",
    "df_avg_delay = avg_delay.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b2ee387-e321-48b0-80bf-55281cdf6839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop_id         8592111\n",
       "hour                 22\n",
       "avg_delay      59.30157\n",
       "std_delay    104.179788\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_delay.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89131fd-d969-4bef-99ee-d7d30e9cc335",
   "metadata": {},
   "source": [
    "## Results visualisation\n",
    "\n",
    "#### First create basic component widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94bab4e5-ceee-444f-ade5-005ad40b147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start graph visualisation\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "import time_utils\n",
    "import path_utils\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44fbdb00-34b8-4f5b-b021-b49799246f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define briefly the graph\n",
    "style = {'description_width': 'initial'}\n",
    "initial_pos = {'description_width':'initial'}\n",
    "\n",
    "#Define stops\n",
    "stop_names = sorted(df_all_nodes['stop_name'].unique())\n",
    "\n",
    "start = widgets.Dropdown(options=stop_names, description='From:')\n",
    "start.value = stop_names[0]\n",
    "\n",
    "end = widgets.Dropdown(options=stop_names, description='To:')\n",
    "end.value = stop_names[-1]\n",
    "\n",
    "#Define run and map buttons\n",
    "button = widgets.Button(description=\"Run\")\n",
    "data_output = widgets.Output()\n",
    "map_output = widgets.Output()\n",
    "\n",
    "# Define inputs\n",
    "hours = widgets.BoundedFloatText(min=0, max=23, value=12, step=1, description='Hour:', style=initial_pos)\n",
    "minutes = widgets.BoundedFloatText(min=0, max=59, value=0, step=1, description='Minute:', style=initial_pos)\n",
    "number_routes = widgets.BoundedIntText(min=0, max=7, value=3, step=1, description='Number of paths to show (0-6):', style=initial_pos)\n",
    "max_trip_len = widgets.BoundedIntText(min=1, max=3, value=2, step=1, description='Max duration (1-3 h):', style=initial_pos)\n",
    "interval = widgets.BoundedFloatText(min=0, max=1, value=0.5, step=0.05, description='Confidence Interval :', style=initial_pos)\n",
    "\n",
    "use_validation = widgets.Checkbox(value=False, description='Show validation',style=style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c411d647-f033-4628-b0d5-2ea2ef8cfe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(path, stop_name):\n",
    "    \"\"\"\n",
    "    Creates a map visualization of a given path and stop name.\n",
    "\n",
    "    Parameters:\n",
    "    path (pandas.DataFrame): DataFrame containing the path information, including start and end stop names, latitudes, and longitudes.\n",
    "    stop_name (str): The name of the stop to be used as the center of the map.\n",
    "\n",
    "    Returns:\n",
    "    go.Figure: A Plotly Figure object representing the map visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Center given the initial stop\n",
    "    center_lat = df_all_nodes[df_all_nodes['stop_name'] == stop_name].iloc[0]['stop_lat']\n",
    "    center_lon = df_all_nodes[df_all_nodes['stop_name'] == stop_name].iloc[0]['stop_lon']\n",
    "\n",
    "    # Get relevant data\n",
    "    starts = path[['start_stop_name', 'start_lat', 'start_lon']]\n",
    "    ends = path[['end_stop_name', 'end_lat', 'end_lon']]\n",
    "    starts.columns = ['stop_name', 'stop_lat', 'stop_lon']\n",
    "    ends.columns = ['stop_name', 'stop_lat', 'stop_lon']\n",
    "    map = pd.concat([starts, ends])\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add lines to the plot\n",
    "    for _, row in path.iterrows():\n",
    "        fig.add_trace(\n",
    "            go.Scattermapbox(mode=\"lines\", lon=[row['start_lon'], row['end_lon']], lat=[row['start_lat'], row['end_lat']], \n",
    "                marker={'size': 8}, text='Walking' if row['walking'] else 'Transport', hoverinfo='text'))\n",
    "    # Add stops \n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(lat=map[\"stop_lat\"], lon=map[\"stop_lon\"], mode='markers', \n",
    "                         marker=dict(size=10, color='blue'), text=map[\"stop_name\"], hoverinfo='text'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        hovermode='closest',\n",
    "        mapbox=dict(bearing=0, center=dict(lat=center_lat, lon=center_lon), pitch=0, zoom=11),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "def print_map(path, center_name):\n",
    "    with map_output:\n",
    "        map_output.clear_output()\n",
    "        display(create_map(path, center_name))\n",
    "\n",
    "def print_data(path):\n",
    "    with data_output:\n",
    "        data_output.clear_output()\n",
    "        display(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dca731-4881-4499-bf4a-ba356d533ecf",
   "metadata": {},
   "source": [
    "#### Define here function to create the map given a path and the path in itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6611fbb4-3385-4002-ac32-44b1c6f02117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_path_data(df, df_all_nodes):\n",
    "    \"\"\"\n",
    "    Merge the start and stop information from the given dataframes.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The dataframe containing the start and end stop IDs.\n",
    "        df_all_nodes (pandas.DataFrame): The dataframe containing all the stop information.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The merged dataframe with start and end stop information.\n",
    "\n",
    "    \"\"\"\n",
    "    # Merge the start stop information\n",
    "    start_stop_info = df.merge(\n",
    "        df_all_nodes[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']],\n",
    "        left_on='start_stop_id',\n",
    "        right_on='stop_id',\n",
    "        how='left'\n",
    "    ).rename(columns={'stop_name': 'start_stop_name', 'stop_lat': 'start_lat', 'stop_lon': 'start_lon'}).drop(columns=['stop_id'])\n",
    "    full_info = start_stop_info.merge(\n",
    "        df_all_nodes[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']],\n",
    "        left_on='end_stop_id',\n",
    "        right_on='stop_id',\n",
    "        how='left'\n",
    "    ).rename(columns={'stop_name': 'end_stop_name', 'stop_lat': 'end_lat', 'stop_lon': 'end_lon'}).drop(columns=['stop_id'])\n",
    "    full_info['walking'] = full_info['trip_id'] == 'None'\n",
    "    \n",
    "    return full_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "658d3560-4d95-40ab-816e-2500f1cba0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate(button):\n",
    "    \"\"\"\n",
    "    Calculate the paths and display the results on the output widgets.\n",
    "\n",
    "    Parameters:\n",
    "    - button: The button widget that triggers the calculation.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve inputs\n",
    "    time = f\"{int(hours.value):02d}:{int(minutes.value):02d}:00\" \n",
    "    max_length = int(max_trip_len.value) * 3600\n",
    "    target = df_all_nodes[df_all_nodes['stop_name'] == end.value]['stop_id'].values[0]\n",
    "    source = df_all_nodes[df_all_nodes['stop_name'] == start.value]['stop_id'].values[0]\n",
    "    use_validate = use_validation.value\n",
    "    confidence_interval = interval.value\n",
    "\n",
    "    # Calculate the paths and the delays corresponding to each delay\n",
    "    paths = get_best_paths(df_all_edge, source, target, time, max_length, int(number_routes.value), confidence_interval, df_avg_delay)\n",
    "    paths.sort(key=lambda path: path[0][\"start_time\"], reverse=True)\n",
    "    all_paths = [pd.DataFrame(path) for path in paths]\n",
    "    paths_proba = [calculate_connection_probability(path, df_avg_delay) for path in paths]\n",
    "    paths_validate = [historic_frequency(path, all_delays, total_delays) for path in paths] if use_validate else []\n",
    "    print(paths_validate)\n",
    "    # No path = return directly\n",
    "    if len(all_paths) == 0:\n",
    "        with data_output:\n",
    "            data_output.clear_output()\n",
    "            display(widgets.Label(\"No paths found.\"))\n",
    "        with map_output:\n",
    "            map_output.clear_output()\n",
    "            display(widgets.Label(\"No paths found.\"))\n",
    "        return\n",
    "    \n",
    "    # Create tab widgets for displaying maps and tables\n",
    "    data_tab = widgets.Tab()\n",
    "    map_tab = widgets.Tab()\n",
    "\n",
    "    # Populate the tabs with outputs\n",
    "    for i, path in enumerate(all_paths):\n",
    "        # Output probabilities\n",
    "        path_cleaned = output_path_data(path, df_all_nodes)\n",
    "        proba_exp = f\"Probability found (exponential): {int(paths_proba[i][0] * 100)}%\"\n",
    "        proba_norm = f\"Probability found (normal): {int(paths_proba[i][1] * 100)}%\"\n",
    "        proba_validate = f\" and in historical data, {int(paths_validate[i] * 100)}% of paths were successful.\" if use_validate else \"\"\n",
    "        proba_output = widgets.Label(f\"{proba_exp}, {proba_validate}\")\n",
    "        proba_norm_output = widgets.Label(f\"{proba_norm}\")\n",
    "\n",
    "        # Data output\n",
    "        data_output_widget = widgets.Output()\n",
    "        path_cleaned_copy = path_cleaned.copy()\n",
    "        with data_output_widget:\n",
    "            display(proba_output)\n",
    "            display(proba_norm_output)\n",
    "            path_cleaned = path_cleaned[['start_stop_name', 'end_stop_name', 'start_time', 'end_time', 'walking']]\n",
    "            path_cleaned.columns = ['Start Stop', 'End Stop', 'Start Time', 'End Time', 'Is Walking']\n",
    "            display(path_cleaned)\n",
    "        data_tab.children += (data_output_widget,)\n",
    "        data_tab.set_title(i, f'Path {i + 1}')\n",
    "\n",
    "        # Map output\n",
    "        map_output_widget = widgets.Output()\n",
    "        with map_output_widget:\n",
    "            display(create_map(path_cleaned_copy, start.value))\n",
    "        map_tab.children += (map_output_widget,)\n",
    "        map_tab.set_title(i, f'Map {i + 1}')\n",
    "    \n",
    "    # Display the tabs\n",
    "    with data_output:\n",
    "        data_output.clear_output()\n",
    "        display(data_tab)\n",
    "    with map_output:\n",
    "        map_output.clear_output()\n",
    "        display(map_tab)\n",
    "\n",
    "button.on_click(calculate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6570a62-2bb2-4673-b1a4-12202d1b11e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23fed5d1a9247e1894c39044ce77cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(BoundedFloatText(value=12.0, description='Hour:', max=23.0, step=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display nicely everything\n",
    "#Create the input widgets box with some padding, margin, and background color\n",
    "input_widgets = widgets.HBox([hours, minutes],\n",
    "                             layout=widgets.Layout(margin='10px 0', padding='10px', border='solid 1px gray', border_radius='5px', background_color='#f0f0f0', justify_content='center'))\n",
    "\n",
    "input_widgets2 = widgets.HBox([max_trip_len, interval],\n",
    "                             layout=widgets.Layout(margin='10px 0', padding='10px', border='solid 1px gray', border_radius='5px', background_color='#f0f0f0', justify_content='center'))\n",
    "\n",
    "nodes_widgets = widgets.HBox([start, end],\n",
    "                             layout=widgets.Layout(margin='10px 0', padding='10px', border='solid 1px gray', border_radius='5px', background_color='#f0f0f0', justify_content='center'))\n",
    "\n",
    "custom_widgets = widgets.HBox([number_routes, use_validation],\n",
    "                             layout=widgets.Layout(margin='10px 0', padding='10px', border='solid 1px gray', border_radius='5px', background_color='#f0f0f0', justify_content='center'))\n",
    "\n",
    "# Group input, nodes, and custom widgets into one vertical box with a button below\n",
    "all_widgets = widgets.VBox([input_widgets, input_widgets2, nodes_widgets, custom_widgets, button],\n",
    "                           layout=widgets.Layout(margin='20px 0', padding='10px', border='solid 1px gray', border_radius='5px', background_color='#e0e0e0', align_items='center'))\n",
    "\n",
    "tab = widgets.Tab([map_output, data_output])\n",
    "tab.set_title(0, 'Map')\n",
    "tab.set_title(1, 'Planning')\n",
    "\n",
    "# Organize the entire dashboard\n",
    "dashboard = widgets.VBox([all_widgets, tab],\n",
    "                         layout=widgets.Layout(border='solid 2px black', border_radius='10px', align_items='center', background_color='#d0d0d0'))\n",
    "\n",
    "# Display the dashboard\n",
    "display(dashboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
